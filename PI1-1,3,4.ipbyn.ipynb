{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 1(15)\n",
    "U danom rječniku SK_rjecnik.txt (koji se nalazi u mapi /usr/share/RacJez/ispitna turing.mathos.hr) uz pomoć regularnih izraza, izvuči samo imenice sa oblikom riječi (riječs naglascima), vrsta i rod, gramatička obilježja i definicijom te ih spremiti u json datoteku.\n",
    "\n",
    "Primjer:\n",
    "```\n",
    "gaj.json{\n",
    "    \"rijec\":\"gȃj\",\n",
    "    \"vrsta\":\"imenica\",\n",
    "    \"rod\":\"m\",\n",
    "    \"gramatička obiljezja\":\"G gája mn. N gájevi G gájēvā\",\n",
    "    \"definicija\":\"mlada šuma; sin. lug¹, šumarak\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "file_path = 'C:/Users/Danijela Valjak/Desktop/3.godina/1.semestar/jezikoslovlje/SK_rjecnik.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Regularni izraz za pronalaženje imeničkih unosa\n",
    "pattern = re.compile(r'(?P<rijec>[\\w\\s]+?)\\s+im\\.\\s(?P<rod>\\w\\.)\\s+(?P<gramatika>.+?)\\s+(?P<definicija>\\[.+?\\].+?)(?=\\ng|\\Z)', re.DOTALL | re.MULTILINE)\n",
    "\n",
    "matches = pattern.finditer(content)\n",
    "\n",
    "nouns_data = []\n",
    "for match in matches:\n",
    "    rijec = match.group('rijec').strip()\n",
    "    vrsta = 'imenica'\n",
    "    rod = match.group('rod').strip()\n",
    "    gramaticka_obiljezja = match.group('gramatika').strip()\n",
    "    definicija = match.group('definicija').strip()\n",
    "    \n",
    "    noun_info = {\n",
    "        \"rijec\": rijec,\n",
    "        \"vrsta\": vrsta,\n",
    "        \"rod\": rod,\n",
    "        \"gramatička obilježja\": gramaticka_obiljezja,\n",
    "        \"definicija\": definicija\n",
    "    }\n",
    "    nouns_data.append(noun_info)\n",
    "\n",
    "# Ispisivanje u JSON datoteku\n",
    "output_file = 'gaj.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(nouns_data, outfile, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 2 (15)\n",
    "Napišite gramatiku obogaćenu značajkama koja opisuje sljedeće rečenice:\n",
    "```\n",
    "Znatiželjan pas je lajao\n",
    "Umiljata mačka glasno prede\n",
    "Umiljata mačka je glasno prela\n",
    "```\n",
    "Vodite računa o sročnosti NP sa VP u broju, rodu i licu. Dakle, gramatika ne bi trebala prihvatiti rečenicu Znatiželjna pas je glasno  lajao ili Znatiželjan pas jeglasno lajala ne treba prihvatiti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk2tikz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk2tikz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_parse\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk2tikz'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk2tikz import show_parse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting grammar.fcfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile grammar.fcfg\n",
    "# grammar.fcfg\n",
    "% start S\n",
    "\n",
    "S -> NP[broj=sg, rod=?r] VP[broj=sg, rod=?r]\n",
    "\n",
    "NP[broj=sg, rod=m] -> Adj[broj=sg, rod=m] N[broj=sg, rod=m]\n",
    "NP[broj=sg, rod=z] -> Adj[broj=sg, rod=z] N[broj=sg, rod=z]\n",
    "\n",
    "VP[broj=sg, rod=m] -> Aux V[broj=sg, rod=m] | V[broj=sg, rod=m]\n",
    "VP[broj=sg, rod=z] -> Aux V[broj=sg, rod=z] | V[broj=sg, rod=z]\n",
    "\n",
    "Adj[broj=sg, rod=m] -> 'Znatiželjan'\n",
    "Adj[broj=sg, rod=z] -> 'Umiljata'\n",
    "\n",
    "N[broj=sg, rod=m] -> 'pas'\n",
    "N[broj=sg, rod=z] -> 'mačka'\n",
    "\n",
    "Aux -> 'je'\n",
    "\n",
    "V[broj=sg, rod=m] -> 'lajao'\n",
    "V[broj=sg, rod=z] -> 'prela' | 'glasno prede' | 'je glasno prela'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Učitavanje parsera\n",
    "cp = nltk.load_parser('grammar.fcfg', trace=0)\n",
    "print(cp.grammar())\n",
    "\n",
    "# Parsiranje rečenice\n",
    "sentence = 'Znatiželjan pas je lajao'\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "# Parsiranje rečenice\n",
    "trees = list(cp.parse(tokens))\n",
    "\n",
    "# Prikazivanje stabla\n",
    "if trees:\n",
    "    tree = trees[0]\n",
    "    tree.pretty_print()\n",
    "else:\n",
    "    print(\"No parse tree found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 3 (15)\n",
    "\n",
    "Implementirajte analizu sentimenta koristeći Bayesov klasifikator za popis filmskih recenzija koje se nalaze u nltk.corpus.movie_reviews. Za značajke pojedine recenzije koristite informaciju sadrži li recenzija najčešćih 2000 riječi iz movie_reviews korpusa. Prijavite rezultate na sljedeći način:Točnost (accuracy) klasifikatora mora biti barem 70%. Prikažite preciznost, odziv i ocjenu za pojedinu kategoriju pozitivnog i negativnog sentimenta.F1\n",
    "Prikažite matricu zbunjenosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to C:\\Users\\Danijela\n",
      "[nltk_data]     Valjak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "from nltk import FreqDist\n",
    "\n",
    "# Učitavanje korpusa movie_reviews\n",
    "nltk.download('movie_reviews')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Izgradnja skupa podataka\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Slučajno promiješajmo dokumente kako bismo izbjegli bilo kakav redoslijed u podacima\n",
    "random.shuffle(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Izgradnja popisa najčešćih 2000 riječi\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words.keys())[:2000]\n",
    "\n",
    "# Funkcija za ekstrakciju značajki\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Točnost (accuracy): 0.7875\n",
      "Preciznost za negativan sentiment: 0.8055555555555556\n",
      "Preciznost za pozitivan sentiment: 0.7663043478260869\n",
      "Odziv za negativan sentiment: 0.8018433179723502\n",
      "Odziv za pozitivan sentiment: 0.7704918032786885\n",
      "F1 ocjena za negativan sentiment: 0.8036951501154733\n",
      "F1 ocjena za pozitivan sentiment: 0.768392370572207\n"
     ]
    }
   ],
   "source": [
    "# Podijela podataka na skup za obuku i skup za testiranje (80-20)\n",
    "train_set = [(document_features(d), c) for (d,c) in documents[:1600]]\n",
    "test_set = [(document_features(d), c) for (d,c) in documents[1600:]]\n",
    "# Treniranje Bayesovog klasifikatora\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluacija klasifikatora\n",
    "print(\"Točnost (accuracy):\", nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "# Prikaz preciznosti, odziva i F1 ocjene za svaku klasu\n",
    "refsets = nltk.collections.defaultdict(set)\n",
    "testsets = nltk.collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "print(\"Preciznost za negativan sentiment:\", nltk.precision(refsets['neg'], testsets['neg']))\n",
    "print(\"Preciznost za pozitivan sentiment:\", nltk.precision(refsets['pos'], testsets['pos']))\n",
    "\n",
    "print(\"Odziv za negativan sentiment:\", nltk.recall(refsets['neg'], testsets['neg']))\n",
    "print(\"Odziv za pozitivan sentiment:\", nltk.recall(refsets['pos'], testsets['pos']))\n",
    "\n",
    "print(\"F1 ocjena za negativan sentiment:\", nltk.f_measure(refsets['neg'], testsets['neg']))\n",
    "print(\"F1 ocjena za pozitivan sentiment:\", nltk.f_measure(refsets['pos'], testsets['pos']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 4(15)\n",
    "Neka je dan sljedeći skup rečenica (korpus).\n",
    "\n",
    "    Google and Facebook are strangling the free press to death.Democracy is the loserYour 60-second guide to security stuff Google touted today at Next'18A Guide to Using Android Without Selling Your Soul to GoogleReview: Lenovo’s Google Smart Display is pretty and intelligentGoogle Maps user spots mysterious object submerged off the coastof Greece - and no-one knows what it isAndroid is better than IOSIn information retrieval, tf–idf or TFIDF, short for termfrequency–inverse document frequencyis a numerical statistic that is intended to reflecthow important a word is to a document in a collection or corpus.It is often used as a weighting factor in searches of informationretrievaltext mining, and user modeling. The tf-idf value increasesproportionallyto the number of times a word appears in the documentand is offset by the frequency of the word in the corpus\n",
    "\n",
    "Učinte sljedeće: 1) Reprezentirajte svaku rečenicu TF-IDF mjerom, te napravite klasteriranje u2 klastera. Ispišite u kojem se klasteru nalazi svaka rečenica iz korpusa. 2) Odredite kojimaklasterima pripadaju sljedeće rečenice:tf-idf is used in used in information retrieval. iOS is betterthan Android.Napomena: vodite računa o normalizaciji tokena i izbacivanju učestalih tokena prijeizračuna TF-IDF mjere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\danijela valjak\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\danijela valjak\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\danijela valjak\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\danijela valjak\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\danijela valjak\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rečenica 'Google and Facebook are strangling the free press to death.' je u klasteru 0\n",
      "Rečenica 'Democracy is the loser' je u klasteru 0\n",
      "Rečenica 'Your 60-second guide to security stuff Google touted today at Next '18' je u klasteru 0\n",
      "Rečenica 'A Guide to Using Android Without Selling Your Soul to Google' je u klasteru 1\n",
      "Rečenica 'Review: Lenovo’s Google Smart Display is pretty and intelligent' je u klasteru 0\n",
      "Rečenica 'Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is' je u klasteru 0\n",
      "Rečenica 'Android is better than IOS' je u klasteru 1\n",
      "Rečenica 'In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval text mining, and user modeling. The tf-idf value increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus' je u klasteru 0\n",
      "Rečenica 'tf-idf is used in used in information retrieval.' pripada klasteru 0\n",
      "Rečenica 'iOS is better than Android.' pripada klasteru 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Korpus rečenica\n",
    "sentences = [\n",
    "    \"Google and Facebook are strangling the free press to death.\",\n",
    "    \"Democracy is the loser\",\n",
    "    \"Your 60-second guide to security stuff Google touted today at Next '18\",\n",
    "    \"A Guide to Using Android Without Selling Your Soul to Google\",\n",
    "    \"Review: Lenovo’s Google Smart Display is pretty and intelligent\",\n",
    "    \"Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\",\n",
    "    \"Android is better than IOS\",\n",
    "    \"In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval text mining, and user modeling. The tf-idf value increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus\"\n",
    "]\n",
    "\n",
    "# 1. Izračun TF-IDF mjere za svaku rečenicu\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "# 2. Klasteriranje rečenica u 2 klastera\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# 3. Ispis u kojem se klasteru nalazi svaka rečenica iz korpusa\n",
    "for i, sentence in enumerate(sentences):\n",
    "    cluster = kmeans.labels_[i]\n",
    "    print(f\"Rečenica '{sentence}' je u klasteru {cluster}\")\n",
    "\n",
    "# 4. Određivanje kojima klasterima pripadaju dodatne rečenice\n",
    "new_sentences = [\n",
    "    \"tf-idf is used in used in information retrieval.\",\n",
    "    \"iOS is better than Android.\"\n",
    "]\n",
    "\n",
    "# Izračunavanje TF-IDF mjere za nove rečenice\n",
    "new_X = vectorizer.transform(new_sentences)\n",
    "\n",
    "# Klasteriranje novih rečenica\n",
    "predicted_clusters = kmeans.predict(new_X)\n",
    "\n",
    "# Ispis rezultata\n",
    "for i, sentence in enumerate(new_sentences):\n",
    "    cluster = predicted_clusters[i]\n",
    "    print(f\"Rečenica '{sentence}' pripada klasteru {cluster}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
